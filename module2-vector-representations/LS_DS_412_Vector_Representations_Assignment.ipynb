{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientistÂ   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "                \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_from_html(html):\n",
    "    soup = BeautifulSoup(html)\n",
    "    return soup.text\n",
    "\n",
    "df['description'].apply(get_text_from_html)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now will save to description column\n",
    "df['description'] = df['description'].apply(get_text_from_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_tokens(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "\n",
    "df['tokens'] = df['description'].apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b\"Job',\n",
       " 'requirements:\\\\nconceptual',\n",
       " 'understanding',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'model',\n",
       " 'like',\n",
       " 'nai\\\\xc2\\\\xa8ve',\n",
       " 'Bayes',\n",
       " 'K',\n",
       " 'Means',\n",
       " 'SVM',\n",
       " 'Apriori',\n",
       " 'Linear/',\n",
       " 'Logistic',\n",
       " 'Regression',\n",
       " 'neural',\n",
       " 'Random',\n",
       " 'Forests',\n",
       " 'decision',\n",
       " 'Trees',\n",
       " 'K',\n",
       " 'NN',\n",
       " 'hand',\n",
       " 'experience',\n",
       " '2',\n",
       " 'them\\\\nintermediate',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'coding',\n",
       " 'skill',\n",
       " 'Python',\n",
       " 'R.',\n",
       " 'ability',\n",
       " 'write',\n",
       " 'function',\n",
       " 'clean',\n",
       " 'efficient',\n",
       " 'datum',\n",
       " 'manipulation',\n",
       " 'mandatory',\n",
       " 'role)\\\\nexposure',\n",
       " 'package',\n",
       " 'like',\n",
       " 'NumPy',\n",
       " 'SciPy',\n",
       " 'Pandas',\n",
       " 'Matplotlib',\n",
       " 'etc',\n",
       " 'Python',\n",
       " 'GGPlot2',\n",
       " 'dplyr',\n",
       " 'tidyR',\n",
       " 'R\\\\nAbility',\n",
       " 'communicate',\n",
       " 'Model',\n",
       " 'finding',\n",
       " 'Technical',\n",
       " 'Non',\n",
       " 'technical',\n",
       " 'stake',\n",
       " 'holders\\\\nhand',\n",
       " 'experience',\n",
       " 'SQL',\n",
       " 'Hive',\n",
       " 'similar',\n",
       " 'programming',\n",
       " 'language\\\\nmust',\n",
       " 'past',\n",
       " 'work',\n",
       " 'GitHub',\n",
       " 'Kaggle',\n",
       " 'publish',\n",
       " 'article\\\\nmaster',\n",
       " 'degree',\n",
       " 'Statistics',\n",
       " 'Mathematics',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'quant',\n",
       " 'specific',\n",
       " 'field.\\\\napply']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4203)\t1\n",
      "  (0, 7787)\t1\n",
      "  (0, 5338)\t1\n",
      "  (0, 9239)\t1\n",
      "  (0, 4584)\t1\n",
      "  (0, 4389)\t1\n",
      "  (0, 4900)\t1\n",
      "  (0, 4459)\t2\n",
      "  (0, 5078)\t1\n",
      "  (0, 9778)\t1\n",
      "  (0, 9764)\t1\n",
      "  (0, 884)\t1\n",
      "  (0, 4725)\t1\n",
      "  (0, 8790)\t1\n",
      "  (0, 636)\t1\n",
      "  (0, 4470)\t1\n",
      "  (0, 4526)\t1\n",
      "  (0, 7666)\t1\n",
      "  (0, 5583)\t1\n",
      "  (0, 7528)\t1\n",
      "  (0, 3184)\t1\n",
      "  (0, 2078)\t1\n",
      "  (0, 9138)\t1\n",
      "  (0, 5979)\t1\n",
      "  (0, 3544)\t1\n",
      "  :\t:\n",
      "  (425, 964)\t2\n",
      "  (425, 3488)\t1\n",
      "  (425, 6641)\t1\n",
      "  (425, 8067)\t1\n",
      "  (425, 1280)\t6\n",
      "  (425, 7477)\t1\n",
      "  (425, 5292)\t1\n",
      "  (425, 7261)\t1\n",
      "  (425, 7901)\t1\n",
      "  (425, 813)\t1\n",
      "  (425, 5620)\t1\n",
      "  (425, 7812)\t1\n",
      "  (425, 4613)\t1\n",
      "  (425, 6588)\t1\n",
      "  (425, 4164)\t1\n",
      "  (425, 7992)\t1\n",
      "  (425, 1633)\t1\n",
      "  (425, 6624)\t1\n",
      "  (425, 1621)\t1\n",
      "  (425, 3807)\t1\n",
      "  (425, 3141)\t1\n",
      "  (425, 8260)\t1\n",
      "  (425, 6562)\t1\n",
      "  (425, 5265)\t2\n",
      "  (425, 4443)\t1\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "dmt = vect.fit_transform(df['description'])\n",
    "print(dmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 9816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0356  04  062  06366  08  10  ...  zenreach  zero  \\\n",
       "0   0    0      0   0     0   0    0      0   0   0  ...         0     0   \n",
       "1   0    0      0   0     0   0    0      0   0   0  ...         0     0   \n",
       "2   0    0      0   0     0   0    0      0   0   0  ...         0     0   \n",
       "3   0    0      0   0     0   0    0      0   0   0  ...         0     0   \n",
       "4   0    0      0   0     0   0    0      0   0   0  ...         0     0   \n",
       "\n",
       "   zeus  zf  zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0     0   0      0       0      0     0           0       0  \n",
       "1     0   0      0       0      0     0           0       0  \n",
       "2     0   0      0       0      0     0           0       0  \n",
       "3     0   0      1       0      0     0           0       0  \n",
       "4     0   0      0       0      0     0           0       0  \n",
       "\n",
       "[5 rows x 9816 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dmt = pd.DataFrame(dmt.todense(), columns=vect.get_feature_names())\n",
    "df_dmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201    1728\n",
       "143     957\n",
       "411     873\n",
       "336     783\n",
       "410     773\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "df_dmt.sum(axis=1).sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "dmt = tfidf.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 9816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  02115   03  0356   04  062  06366   08   10  ...  zenreach  zero  \\\n",
       "0  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "1  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "2  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "3  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "4  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "\n",
       "   zeus   zf     zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "1   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "2   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "3   0.0  0.0  0.104421     0.0    0.0   0.0         0.0     0.0  \n",
       "4   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 9816 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dmt = pd.DataFrame(dmt.todense(), columns=tfidf.get_feature_names())\n",
    "df_dmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(df_dmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.30661601, 1.31543483, 1.32223717, 1.32243061, 1.32243061]]),\n",
       " array([[261, 173, 151,  33, 378]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Machine Learning Engineer with a strong web development background\"\n",
    "nn.kneighbors(tfidf.transform([test]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'The Data Science Engineer, Mintel Futures is a core part of Mintel\\\\xe2\\\\x80\\\\x99s data science team that will have the opportunity to work on a wide array of initiatives across varying aspects of Mintel\\\\xe2\\\\x80\\\\x99s business and data. This individual will help manage the full analytics lifecycle of advanced projects; help to identify new, impactful ways to apply machine learning to Mintel\\\\xe2\\\\x80\\\\x99s data; work alongside data scientists and business stakeholders to implement solutions that provide valuable insights; and aide in the design and development of a modern data analytics environment.\\\\n\\\\nWhat You Will Do:\\\\n\\\\nPlay an integral role in shaping the underlying technology environment for Mintel\\\\xe2\\\\x80\\\\x99s fast growing team of data scientists and data analysts\\\\nAssist in the acquisition and management of a variety of data sources for large-scale analysis\\\\nIdentify opportunities for predictive modeling or other machine learning techniques and experiment with solutions that focus on adding value to our clients and analysts\\\\nWork alongside software engineers and other data scientists to ensure the proper deployment, management and monitoring of machine learning models and/or other data pipelines in Mintel\\\\xe2\\\\x80\\\\x99s production platforms\\\\nGrow the technical and engineering capabilities of other data scientists and data analysts on the team\\\\nDevelop engineering best practices, documentation and process flows that facilitate collaboration and knowledge transfer\\\\nContinually learn - as a part of a fluid, innovation focused team, you will stay current on emerging data science and data engineering technologies\\\\n\\\\n\\\\nWhat We Are Looking For:\\\\n\\\\n3+ years professional experience with building data focused solutions (integrations, pipelines, data warehousing, etc.)\\\\n1+ years professional experience as a data scientist or machine learning engineer preferred and/or having demonstrable analytical capability and working knowledge of data science principles\\\\nProficient engineer with the ability to lead the deployment of machine learning or other analytical models\\\\nExpert level SQL skills and expert level proficiency in at least one programming language (Python, C++, Java, etc.)\\\\nStrong communication skills with the ability to converse with both technical and non-technical stakeholders\\\\nTeam player with a collaborative nature\\\\nStrong work ethic with an inherent sense of ownership and responsibility\\\\nExperience building data solutions in at least one public cloud environment, AWS or GCP preferred\\\\nAdvanced degree holder in a STEM or related quantitative discipline preferred\\\\nEqual Opportunity Employer: Race/Color/Sex/Sexual Orientation/Gender Identity/Religion/National Origin/Disability/Vets'\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[261]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'We are hiring a remote Data Scientist with strong Machine Learning background and about 3+ years of experience.\\\\nREQUIREMENTS\\\\nDegree Required\\\\nDeep understanding of, and experience with, machine learning models and data analysis\\\\nDeep understanding of both supervised and unsupervised learning methods\\\\nExperience with building end-to-end machine learning systems in production\\\\nStrong proficiency writing production-quality code\\\\nExperience handling large-scale data, big data platforms, and distributed systems\\\\nFOR IMMEDIATE CONSIDERATION, EMAIL RESUME WITH FIRST AND LAST NAME, HOME LOCATION, CELL AND EMAIL ADDRESS TO: ds@executecrecruiters.com. Please, No Calls and Recruiters do not send me your candidates.'\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[173]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
